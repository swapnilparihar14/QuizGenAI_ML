{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install git+https://github.com/boudinfl/pke.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade spacy==2.2.4\n",
    "#pip show spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extractor Module\n",
    "   1. The process of extraction of keywords from a text is an unsupervised task. It can be done using  **Statistical models**  and **Graph-based models** \n",
    "   2. PKE unsupervised library provides us with 3 statistical models and 6 graph based models.\n",
    "   3. The notebook compares the performances of all the well known models for the given input text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "   1. https://towardsdatascience.com/keyword-extraction-python-tf-idf-textrank-topicrank-yake-bert-7405d51cd839\n",
    "   2. https://boudinfl.github.io/pke/build/html/unsupervised.html\n",
    "   3. https://arxiv.org/abs/1803.08721\n",
    "   4. https://github.com/MaartenGr/KeyBERT#usage\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\16692\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\16692\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16692\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import itertools\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "import pke\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import traceback\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the sample input text\n",
    "text = \"\"\"There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”\"\"\"\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: spacy\n",
      "Version: 2.2.4\n",
      "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
      "Home-page: https://spacy.io\n",
      "Author: Explosion\n",
      "Author-email: contact@explosion.ai\n",
      "License: MIT\n",
      "Location: c:\\users\\16692\\anaconda3\\lib\\site-packages\n",
      "Requires: murmurhash, blis, setuptools, numpy, requests, cymem, preshed, plac, wasabi, srsly, catalogue, thinc, tqdm\n",
      "Required-by: pke, en-core-web-sm\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_limit(no_of_words,user_limit = 0):\n",
    "    if user_limit ==0:\n",
    "        return round(no_of_words/15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_MultipartiteRank(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based MultipartiteRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        # Selecting the extractor and loading the input text in it\n",
    "        extractor = pke.unsupervised.MultipartiteRank()\n",
    "        extractor.load_document(input=text)\n",
    "        \n",
    "        # It can extract these three types of \"phrases\" from the input text\n",
    "        pos = {'VERB', 'ADJ', 'NOUN'}\n",
    "        convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "        \n",
    "        stoplist = list(string.punctuation)\n",
    "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "        stoplist += stopwords.words('english')\n",
    "        \n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "        \n",
    "        for partsofspeech in pos:\n",
    "            extractor.candidate_selection(pos=partsofspeech, stoplist=stoplist)\n",
    "            extractor.candidate_weighting(alpha=1.1, threshold=0.75, method='average')\n",
    "            keyphrases = extractor.get_n_best(n=keyword_limit)\n",
    "            \n",
    "            for val in keyphrases:\n",
    "                out[(val[0],convert_pos[partsofspeech])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "{('oceans', 'n'): 0.10302416744017867, ('undersea volcanoes', 'n'): 0.0884645405518853, ('plate boundaries', 'n'): 0.08432931637295996, ('plate', 'n'): 0.07096028545990593, ('rock', 'n'): 0.058991754010652334, ('crust', 'n'): 0.053535846868880216, ('example', 'n'): 0.051820409215493114, ('cracks', 'n'): 0.03541664826727955, ('activity', 'n'): 0.035349980756700164, ('surface', 'n'): 0.033796845675054095, ('subduction zone', 'n'): 0.033354679877531386, ('volcanoes', 'n'): 0.030537514820040943, ('lot', 'n'): 0.028607846755605654, ('volcanoes form', 'n'): 0.028531446593391147, ('oceans', 'a'): 0.07640427896367138, ('plate boundaries', 'a'): 0.07453170589051847, ('divergent', 'a'): 0.061340552016611725, ('plate', 'a'): 0.05940852072369033, ('undersea volcanoes', 'a'): 0.05789660999344903, ('rock', 'a'): 0.044473208150754846, ('crust', 'a'): 0.043202585567860684, ('many', 'a'): 0.04081820498072136, ('molten', 'a'): 0.03498437668426168, ('boundaries', 'a'): 0.03187732713063273, ('volcanic', 'a'): 0.02855944733961786, ('continental', 'a'): 0.02604253223836374, ('subduction zone', 'a'): 0.024617546141526954, ('volcanoes', 'a'): 0.02421280030283321, ('oceans', 'v'): 0.062263894607223105, ('plate boundaries', 'v'): 0.06039066732907362, ('plate', 'v'): 0.04908828123944462, ('divergent', 'v'): 0.046267993112105506, ('forming', 'v'): 0.04111700613900309, ('rock', 'v'): 0.03983249387654939, ('undersea volcanoes', 'v'): 0.03731941776981998, ('crust', 'v'): 0.036248824129855216, ('molten', 'v'): 0.028888812384024683, ('many', 'v'): 0.028522429462592667, ('boundaries', 'v'): 0.025781745130012114, ('called', 'v'): 0.02349410976299906, ('volcanoes', 'v'): 0.023389442618402416, ('pull', 'v'): 0.022419006643047832}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_MultipartiteRank(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_PositionRank(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based PositionRank algorithm\n",
    "       @input: (text)-Block of continous text on a single topic \n",
    "       @Hyperparameters: ()-None\n",
    "       @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out = {}\n",
    "    pos = {'NOUN', 'VERB', 'ADJ'}\n",
    "    convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "    try:\n",
    "    # define the grammar for selecting the keyphrase candidates\n",
    "        grammar = \"NP: {<ADJ>*<NOUN|PROPN>+}\"\n",
    "\n",
    "        # 1. create a PositionRank extractor.\n",
    "        extractor = pke.unsupervised.PositionRank()\n",
    "        #print(\"Keyword extraction Using the PositionRank model\")\n",
    "\n",
    "        # 2. load the content of the document.\n",
    "        extractor.load_document(input=text, language='en', normalization=None)\n",
    "\n",
    "        # 3. select the noun phrases up to 3 words as keyphrase candidates.\n",
    "        extractor.candidate_selection(grammar=grammar,maximum_word_number=3)\n",
    "\n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "\n",
    "        # 4. weight the candidates using the sum of their word's scores that are\n",
    "        #    computed using random walk biaised with the position of the words\n",
    "        #    in the document. In the graph, nodes are words (nouns and\n",
    "        #    adjectives only) that are connected if they occur in a window of\n",
    "        #    10 words.\n",
    "        for partsofspeech in pos:\n",
    "            extractor.candidate_weighting(window=10,pos=partsofspeech)\n",
    "            # 5. get the 10-highest scored candidates as keyphrases\n",
    "            keyphrases = extractor.get_n_best(n=keyword_limit)\n",
    "            for val in keyphrases:\n",
    "                out[(val[0],convert_pos[partsofspeech])] = val[1]\n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "{('convergent plate boundaries', 'n'): 0.2740242877458622, ('divergent plate boundaries', 'n'): 0.2554064196108812, ('plate melts', 'n'): 0.16350633422275607, ('divergent plate', 'n'): 0.14872209540330936, ('tectonic plate', 'n'): 0.14872209540330936, ('pacific plate', 'n'): 0.14872209540330936, ('many undersea volcanoes', 'n'): 0.11632726026346255, ('volcanoes form', 'n'): 0.1085462034519323, ('volcanoes forms', 'n'): 0.10739561111920042, ('boundaries', 'n'): 0.10668432420757185, ('many volcanoes', 'n'): 0.09300551647238586, ('volcanoes', 'n'): 0.09300551647238586, ('ocean crust', 'n'): 0.07525084121064403, ('subduction zone', 'n'): 0.0713412828131566, ('divergent plate boundaries', 'a'): 0.24993648305141067, ('divergent plate', 'a'): 0.1805063660249963, ('convergent plate boundaries', 'a'): 0.17833335194555583, ('tectonic plate', 'a'): 0.12482526453961151, ('plate melts', 'a'): 0.10640798574365178, ('pacific plate', 'a'): 0.09673440331095517, ('many undersea volcanoes', 'a'): 0.09486672258669855, ('many volcanoes', 'a'): 0.0797146740675372, ('volcanoes form', 'a'): 0.07095050219788457, ('volcanoes forms', 'a'): 0.07022344919336423, ('boundaries', 'a'): 0.06943011702641436, ('continental crust', 'a'): 0.0616952706655091, ('oceanic crust', 'a'): 0.06161454798057382, ('volcanoes', 'a'): 0.060782385805384684, ('divergent plate boundaries', 'v'): 0.2219776367551576, ('convergent plate boundaries', 'v'): 0.15964697732398953, ('divergent plate', 'v'): 0.1595585407748037, ('tectonic plate', 'v'): 0.11081942913414489, ('plate melts', 'v'): 0.09493990769949381, ('pacific plate', 'v'): 0.08632590964051999, ('many undersea volcanoes', 'v'): 0.08459806768918565, ('many volcanoes', 'v'): 0.07106780577422493, ('volcanoes form', 'v'): 0.06716865877537363, ('volcanoes forms', 'v'): 0.06293991695652118, ('boundaries', 'v'): 0.062419095980353924, ('continental crust', 'v'): 0.054969820366795326, ('oceanic crust', 'v'): 0.05486770255784498, ('volcanoes', 'v'): 0.05450668980538872}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_PositionRank(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_TopicRank(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based TopicRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        # Selecting the extractor and loading the input text in it\n",
    "        extractor = pke.unsupervised.TopicRank()\n",
    "        extractor.load_document(input=text)\n",
    "        \n",
    "        # It can extract these three types of \"phrases\" from the input text\n",
    "        pos = {'NOUN','VERB','ADJ'}\n",
    "        convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "        \n",
    "        stoplist = list(string.punctuation)\n",
    "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "        stoplist += stopwords.words('english')\n",
    "        \n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "        \n",
    "        for partsofspeech in pos:\n",
    "            extractor.candidate_selection(pos=partsofspeech, stoplist=stoplist)\n",
    "            extractor.candidate_weighting(threshold=0.74, method='average')\n",
    "            try:\n",
    "                keyphrases = extractor.get_n_best(n=keyword_limit)\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            for val in keyphrases:\n",
    "                out[(val[0],convert_pos[partsofspeech])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "{('undersea volcanoes', 'n'): 0.11166551175242785, ('plate', 'n'): 0.09315379045958856, ('crust', 'n'): 0.09304248626350621, ('plate boundaries', 'n'): 0.08217261390177774, ('rock', 'n'): 0.08039706362726223, ('subduction zone', 'n'): 0.05670403385765736, ('cracks', 'n'): 0.04873040443332037, ('surface', 'n'): 0.04765114022376231, ('edge', 'n'): 0.04213339252919163, ('earth', 'n'): 0.03292826335901927, ('lava', 'n'): 0.027723966984365897, ('hardens', 'n'): 0.027506314914308515, ('line', 'n'): 0.026729025642243043, ('oceans', 'n'): 0.026024166094772424}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_TopicRank(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_SingleRank(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based SingleRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        # Selecting the extractor and loading the input text in it\n",
    "        extractor = pke.unsupervised.SingleRank()\n",
    "        extractor.load_document(input=text)\n",
    "        \n",
    "        # It can extract these three types of \"phrases\" from the input text\n",
    "        pos = {'NOUN','VERB','ADJ'}\n",
    "        convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "        \n",
    "        \n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "        \n",
    "        for partsofspeech in pos:\n",
    "            extractor.candidate_selection(pos=partsofspeech)\n",
    "            extractor.candidate_weighting(window=10,pos=partsofspeech)\n",
    "            try:\n",
    "                keyphrases = extractor.get_n_best(n=keyword_limit)\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            for val in keyphrases:\n",
    "                out[(val[0],convert_pos[partsofspeech])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "{('convergent plate boundaries', 'n'): 0.23303142898104937, ('plate boundaries', 'n'): 0.21164701592346064, ('plate melts', 'n'): 0.1529143597366299, ('plate', 'n'): 0.13009334726510488, ('volcanoes form', 'n'): 0.12815494942708625, ('undersea volcanoes', 'n'): 0.11271267981251763, ('subduction zone', 'n'): 0.10508687953426911, ('ocean crust', 'n'): 0.09987348313128479, ('volcanoes', 'n'): 0.0937939313158603, ('boundaries', 'n'): 0.08155514865835575, ('crust', 'n'): 0.06343458355054288, ('rock', 'n'): 0.05756125315613764, ('cracks', 'n'): 0.036838897581556417, ('oceans', 'n'): 0.03643845958074192, ('convergent plate boundaries', 'a'): 0.2003278639275302, ('plate boundaries', 'a'): 0.18362919326157334, ('plate melts', 'a'): 0.11854193599325631, ('plate', 'a'): 0.10132062811416108, ('volcanoes form', 'a'): 0.10071571298013135, ('ocean crust', 'a'): 0.09923626942619934, ('undersea volcanoes', 'a'): 0.08914418592765692, ('boundaries', 'a'): 0.08231004514741228, ('subduction zone', 'a'): 0.08016783278090316, ('volcanoes', 'a'): 0.07378101712173674, ('crust', 'a'): 0.050770729003566877, ('oceans', 'a'): 0.04846510042263247, ('rock', 'a'): 0.04395610915484722, ('divergent', 'a'): 0.035050688013882274, ('convergent plate boundaries', 'v'): 0.1769726547302964, ('plate boundaries', 'v'): 0.16232703831227197, ('volcanoes form', 'v'): 0.12137223945529109, ('plate melts', 'v'): 0.10412028511773412, ('plate', 'v'): 0.08904060027106543, ('ocean crust', 'v'): 0.08700388975071535, ('undersea volcanoes', 'v'): 0.0810357841228972, ('boundaries', 'v'): 0.07328791804120652, ('subduction zone', 'v'): 0.07289491229976712, ('volcanoes', 'v'): 0.06766458044351673, ('forming', 'v'): 0.05370912901177437, ('crust', 'v'): 0.04518314677284599, ('oceans', 'v'): 0.041820302977869366, ('rock', 'v'): 0.03798457743796277}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_SingleRank(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_TextRank(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based TextRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        # Selecting the extractor and loading the input text in it\n",
    "        extractor = pke.unsupervised.TextRank()\n",
    "        extractor.load_document(input=text)\n",
    "        \n",
    "        # It can extract these three types of \"phrases\" from the input text\n",
    "        pos = {'NOUN','VERB','ADJ'}\n",
    "        convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "        \n",
    "        \n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "        \n",
    "        for partsofspeech in pos:\n",
    "            #extractor.candidate_selection(pos=partsofspeech)\n",
    "            extractor.candidate_weighting(window=3,pos=partsofspeech,top_percent=1)\n",
    "            try:\n",
    "                keyphrases = extractor.get_n_best(n=keyword_limit)\n",
    "            except ZeroDivisionError:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            for val in keyphrases:\n",
    "                out[(val[0],convert_pos[partsofspeech])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Candidates are generated using 1-top\n",
      "WARNING:root:Candidates are generated using 1-top\n",
      "WARNING:root:Candidates are generated using 1-top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "{('convergent plate boundaries', 'n'): 0.20261913074467355, ('volcanoes form', 'n'): 0.17104580408252842, ('undersea volcanoes', 'n'): 0.17104480408252842, ('subduction zones lined', 'n'): 0.15515425364174637, ('plate boundaries', 'n'): 0.14458154907457962, ('volcanoes', 'n'): 0.13388874073202472, ('plate melts', 'n'): 0.11991796724229746, ('subduction zone', 'n'): 0.11799587029124269, ('ocean crust', 'n'): 0.10862324009019227, ('plates', 'n'): 0.08654592740448569, ('earth', 'n'): 0.0862973872177052, ('crust', 'n'): 0.06991635638680654, ('boundaries', 'n'): 0.05803727167009392, ('forming rock', 'n'): 0.046008490874786756, ('convergent plate boundaries', 'a'): 0.17504122795861413, ('divergent plate boundaries', 'a'): 0.15646467015122495, ('many volcanoes form', 'a'): 0.13364791310835694, ('many undersea volcanoes', 'a'): 0.13364650310835693, ('plate boundaries', 'a'): 0.13111766295848232, ('volcanoes form', 'a'): 0.12687550372300352, ('undersea volcanoes', 'a'): 0.12687450372300352, ('long subduction zones lined', 'a'): 0.1250497374825538, ('subduction zones lined', 'a'): 0.11827773809720034, ('ocean crust', 'a'): 0.1036994947569077, ('volcanoes', 'a'): 0.09889430856344295, ('plate melts', 'a'): 0.09090765367198378, ('subduction zone', 'a'): 0.09029522293763978, ('tectonic plates', 'a'): 0.0723312958645946, ('convergent plate boundaries', 'v'): 0.16290560051737848, ('divergent plate boundaries', 'v'): 0.1456169906728293, ('many volcanoes form', 'v'): 0.12505492276321645, ('many undersea volcanoes', 'v'): 0.12505351276321644, ('plate boundaries', 'v'): 0.12202733332284099, ('volcanoes form', 'v'): 0.11875191525777738, ('undersea volcanoes', 'v'): 0.11875091525777738, ('long subduction zones lined', 'v'): 0.11615482232726987, ('subduction zones lined', 'v'): 0.10985222482183077, ('earth ’s surface', 'v'): 0.10011546592105584, ('ocean crust', 'v'): 0.0965102746711468, ('volcanoes', 'v'): 0.09293610252288867, ('plate melts', 'v'): 0.08460513901140879, ('subduction zone', 'v'): 0.08403509208694207}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_TextRank(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_YAKE(text):\n",
    "    \"\"\"Extracts keywords from input text using Graph based TextRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        # Selecting the extractor and loading the input text in it\n",
    "        extractor = pke.unsupervised.YAKE()\n",
    "        extractor.load_document(input=text,language='en', normalization=None)\n",
    "        \n",
    "        # It can extract these three types of \"phrases\" from the input text\n",
    "        #pos = {'NOUN','VERB','ADJ'}\n",
    "        #convert_pos = {'VERB': 'v', 'NOUN': 'n','ADJ': 'a'}\n",
    "        \n",
    "        stoplist = list(string.punctuation)\n",
    "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "        stoplist = stopwords.words('english')\n",
    "        \n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "        \n",
    "        extractor.candidate_selection(n=3, stoplist=stoplist)\n",
    "        extractor.candidate_weighting(window=3,stoplist=stoplist,use_stems=False)\n",
    "        keyphrases = extractor.get_n_best(n=keyword_limit*2,threshold=0.8)\n",
    "\n",
    "                \n",
    "            \n",
    "        for val in keyphrases:\n",
    "            out[(val[0])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "{'atlantic ridge': 0.04599435489729826, 'divergent plate': 0.05051811913746707, 'plate': 0.05675656522364285, 'divergent plate boundary': 0.0681994202941495, 'crust': 0.0818394401636323, 'volcanoes': 0.08644397137081854, 'divergent': 0.09255724673191565, 'plate boundaries': 0.09885746497827541, 'atlantic ocean': 0.1026581477748343, 'atlantic': 0.10929097903133549, 'molten rock': 0.11286214022530992, 'rock': 0.12285379179720222, 'boundaries': 0.12594121245326878, 'pacific': 0.1275454360674287, 'volcanic activity': 0.1601944782681947, 'molten': 0.17157472445232513, 'called': 0.17436246924346388, 'along': 0.19623912640704033, 'subduction': 0.19820853169223906, 'mid': 0.20116891760408584, 'ridge': 0.20116891760408584, 'oceans': 0.20903296229448917, 'pacific plate': 0.2102683729058276, 'continental crust': 0.2177600078479168, 'pacific ring': 0.2181614702241551, 'lot': 0.22856222633236592, 'activity': 0.22856222633236592, 'volcanoes form': 0.24117553684966264}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_YAKE(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keyBERTNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading keybert-0.2.0.tar.gz (12 kB)\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from keyBERT) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from keyBERT) (1.18.5)\n",
      "Collecting transformers<5.0.0,>=3.1.0\n",
      "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\16692\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keyBERT) (4.47.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keyBERT) (1.7.0)\n",
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\16692\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keyBERT) (1.5.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\16692\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keyBERT) (3.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keyBERT) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keyBERT) (2.1.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\16692\\appdata\\roaming\\python\\python38\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (20.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\16692\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\16692\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (2020.6.8)\n",
      "Requirement already satisfied: future in c:\\users\\16692\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keyBERT) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\16692\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keyBERT) (3.7.4.2)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: click in c:\\users\\16692\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keyBERT) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\16692\\anaconda3\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\16692\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keyBERT) (3.0.4)\n",
      "Building wheels for collected packages: keyBERT, sentence-transformers\n",
      "  Building wheel for keyBERT (setup.py): started\n",
      "  Building wheel for keyBERT (setup.py): finished with status 'done'\n",
      "  Created wheel for keyBERT: filename=keybert-0.2.0-py3-none-any.whl size=10617 sha256=571899ce64c672ee4f80bb602c52b6c36ea23562672316f07c714a9fb25c99a5\n",
      "  Stored in directory: c:\\users\\16692\\appdata\\local\\pip\\cache\\wheels\\ce\\ff\\82\\42c5c7daa648a5bb132941030c36a00e35b713e550e821b58b\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-py3-none-any.whl size=114312 sha256=be32c2dfb6e8f45f4f7e255c500f80dc9f502480d3bdb7d3c3c9acbc09c27d4a\n",
      "  Stored in directory: c:\\users\\16692\\appdata\\local\\pip\\cache\\wheels\\28\\cb\\ae\\360fe121dc748add4fabecd46e78c31d1ea2402d341f97e2dc\n",
      "Successfully built keyBERT sentence-transformers\n",
      "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers, keyBERT, dataclasses\n",
      "Successfully installed dataclasses-0.6 keyBERT-0.2.0 sacremoses-0.0.45 sentence-transformers-1.0.4 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install keyBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”']\n"
     ]
    }
   ],
   "source": [
    "array_text = []\n",
    "text_clean = text.replace(\"\\n\", \" \").replace(\"\\'\", \"\")\n",
    "array_text.append(text_clean[0:5000])\n",
    "print(array_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_KeyBERT(text):\n",
    "    \"\"\"Extracts keywords from input text using Word Embedding based TextRank algorithm\n",
    "           @input: (text)-Block of continous text on a single topic \n",
    "           @Hyperparameters: ()-None\n",
    "           @Output: (out)-Dictionary with the syntax {('keyword','partofspeech'):weightage}\"\"\"\n",
    "    out={}\n",
    "    try:\n",
    "        kw_extractor = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "        keyword_limit = get_keyword_limit(len(text.split()))\n",
    "\n",
    "        keywords = kw_extractor.extract_keywords(text, stop_words='english', top_n = keyword_limit*2,keyphrase_ngram_range=(1,2))\n",
    "    \n",
    "        for val in keywords:\n",
    "            out[(val[0])] = val[1]\n",
    "                \n",
    "    except:\n",
    "        out = {}\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "{'crust volcanoes': 0.6738, 'erupts volcanoes': 0.671, 'ocean tectonic': 0.6641, 'lined volcanoes': 0.6511, 'forming magma': 0.6431, 'volcanic activity': 0.6322, 'volcanoes form': 0.6299, 'volcanoes forms': 0.6256, 'lot volcanic': 0.6181, 'magma erupts': 0.6082, 'volcanic': 0.5989, 'volcanic arc': 0.5978, 'volcanoes mid': 0.5865, 'volcanoes pacific': 0.5854, 'volcanoes': 0.5847, 'make volcanic': 0.5788, 'volcanoes line': 0.5709, 'line volcanoes': 0.5701, 'tectonic plate': 0.5677, 'molten rock': 0.5611, 'undersea volcanoes': 0.5603, 'tectonic plates': 0.5603, 'ocean crust': 0.5493, 'oceanic crust': 0.5455, 'tectonic': 0.5351, 'boundaries tectonic': 0.5274, 'magma': 0.5178, 'thicker oceanic': 0.5079}\n"
     ]
    }
   ],
   "source": [
    "k = get_keywords_KeyBERT(text)\n",
    "print(len(k))\n",
    "print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
